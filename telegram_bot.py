# telegram_bot.py

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from langchain_ollama import OllamaLLM
from langchain_core.prompts import ChatPromptTemplate

# === CONFIGURATION ===
TELEGRAM_TOKEN = "8095470447:AAFRiTYrn7JSUhMl_8iMgZCN3rLw404SuMY"  # ‚Üê Mets ton vrai token ici !
OLLAMA_MODEL = "phi3"  # ou "phi3", etc.

# === CHATBOT LOCAL (Ollama + LangChain) ===
template = """
Tu es un assistant utile. R√©ponds toujours en fran√ßais.

R√®gles strictes :
1. Si la question est simple (calcul, d√©finition, traduction, capitale, etc.), r√©ponds **directement et bri√®vement**.
2. Si l'utilisateur dit "explique", "d√©veloppe", ou "en d√©tail", alors donne une r√©ponse plus compl√®te.
3. Jamais d'explication non demand√©e.
4. Ne r√©p√®te pas la question.
5. Ne dis pas "R√©ponse :".

Exemples :
- Question : "2+2" ‚Üí R√©ponse : "4"
- Question : "Capitale de la France ?" ‚Üí R√©ponse : "Paris"
- Question : "Qui est Einstein ?" ‚Üí R√©ponse : "Physicien c√©l√®bre pour la relativit√©."
- Question : "Explique qui est Einstein" ‚Üí R√©ponse : "Albert Einstein √©tait un physicien th√©orique..."

Historique : {context}

Question : {question}

R√©ponse :
"""

model = OllamaLLM(model=OLLAMA_MODEL)
prompt = ChatPromptTemplate.from_template(template)
chain = prompt | model

# Stocker l'historique par utilisateur (si plusieurs personnes parlent)
user_contexts = {}  # {user_id: "historique..."}

# === GESTION DES COMMANDES TELEGRAM ===

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_contexts[user_id] = ""  # Initialiser l'historique
    await update.message.reply_text("Hello! I'm your AI assistant. Ask me anything! ü§ñ")

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_id = update.effective_user.id
    user_input = update.message.text

    # Initialiser l'historique si nouveau
    if user_id not in user_contexts:
        user_contexts[user_id] = ""

    context = user_contexts[user_id]

    try:
        # Faire r√©pondre le mod√®le
        print(f"[User {user_id}] {user_input}")
        response = chain.invoke({"context": context, "question": user_input})
        response_text = str(response).strip()

        # Envoyer la r√©ponse
        await update.message.reply_text(response_text)

        # Mettre √† jour l'historique
        user_contexts[user_id] += f"\nUser: {user_input}\nAI: {response_text}"
        # Garder seulement les 2000 derniers caract√®res
        user_contexts[user_id] = user_contexts[user_id][-2000:]

    except Exception as e:
        print(f"Error: {e}")
        await update.message.reply_text("Sorry, I couldn't process your request.")

# === LANCEMENT DU BOT ===
if __name__ == "__main__":
    print("üöÄ Starting Telegram bot...")

    # Cr√©er l'application
    app = Application.builder().token(TELEGRAM_TOKEN).build()

    # Ajouter les gestionnaires
    app.add_handler(CommandHandler("start", start))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # D√©marrer le bot
    print("‚úÖ Bot is running... Waiting for messages.")
    app.run_polling()